# Practice Projects Directory

This directory contains actual project code and configuration files during the learning process.

## ğŸ“‚ Project Structure

```
projects/
â”œâ”€â”€ 01-first-iceberg-table/         # âœ… Project 1: First Iceberg Table (Completed)
â”‚   â”œâ”€â”€ docker-compose.yml          # Docker environment configuration
â”‚   â”œâ”€â”€ manage.sh                   # Environment management script
â”‚   â”œâ”€â”€ notebooks/                  # Jupyter tutorials and examples
â”‚   â”‚   â””â”€â”€ iceberg-tutorial.ipynb  # Complete Iceberg tutorial
â”‚   â”œâ”€â”€ scripts/                    # Test scripts
â”‚   â”œâ”€â”€ warehouse/                  # Iceberg table storage location
â”‚   â”œâ”€â”€ README.md                   # Detailed project documentation
â”‚   â””â”€â”€ SPARK_VS_ICEBERG.md        # Spark vs Iceberg relationship documentation
â”œâ”€â”€ 02-schema-evolution/            # Project 2: Schema Evolution Experiments (Planned)
â”‚   â”œâ”€â”€ scripts/                    # Demo scripts
â”‚   â”œâ”€â”€ test-data/                  # Test data
â”‚   â””â”€â”€ README.md                   # Project documentation
â”œâ”€â”€ 03-time-travel/                 # Project 3: Time Travel Features (Planned)
â”‚   â”œâ”€â”€ demo/                       # Demo code
â”‚   â””â”€â”€ README.md                   # Project documentation
â”œâ”€â”€ 04-cloud-integration/           # Project 4: Cloud Platform Integration (Planned)
â”‚   â”œâ”€â”€ aws/                        # AWS configuration
â”‚   â”œâ”€â”€ azure/                      # Azure configuration
â”‚   â””â”€â”€ README.md                   # Project documentation
â””â”€â”€ 05-production-pipeline/         # Project 5: Production Data Pipeline (Planned)
    â”œâ”€â”€ spark-jobs/                 # Spark jobs
    â”œâ”€â”€ monitoring/                 # Monitoring configuration
    â””â”€â”€ README.md                   # Project documentation
```

## ğŸ¯ Project Completion Status

### âœ… Project 1: First Iceberg Table (Completed)
- **Learning Goal**: Master basic Iceberg table creation and operations âœ…
- **Tech Stack**: Docker, Spark, Iceberg, Jupyter Notebook âœ…
- **Completion Time**: Completed
- **Main Achievements**:
  - âœ… Built complete Docker development environment
  - âœ… Successfully integrated Spark 3.5.0 + Iceberg 1.4.3
  - âœ… Created interactive Jupyter tutorial
  - âœ… Implemented data insertion, querying and metadata exploration
  - âœ… Resolved Python version conflicts and permission issues
  - âœ… Verified partitioning and ACID transaction features

### ğŸ”„ Project 2: Schema Evolution Experiments (Planned)
- **Learning Goal**: Understand and practice schema evolution functionality
- **Tech Stack**: Spark SQL, Schema management
- **Estimated Time**: 2-3 days

### ğŸ”„ Project 3: Time Travel Features (Planned)
- **Learning Goal**: Master snapshot management and time travel queries
- **Tech Stack**: Spark SQL, Snapshot API
- **Estimated Time**: 2 days

### ğŸ”„ Project 4: Cloud Platform Integration (Planned)
- **Learning Goal**: Deploy and use Iceberg in cloud environments
- **Tech Stack**: AWS S3/Glue, or Azure ADLS
- **Estimated Time**: 3-5 days

### ğŸ”„ Project 5: Production Data Pipeline (Planned)
- **Learning Goal**: Build complete production-grade data pipeline
- **Tech Stack**: Spark, Cloud services, Monitoring
- **Estimated Time**: 1-2 weeks

## ğŸ“‹ Project 1 Completion Results âœ…

### ğŸ› ï¸ Technical Environment
- **Dockerized Deployment**: One-click Spark + Iceberg environment
- **Jupyter Integration**: Interactive learning and experimentation platform
- **Permission Management**: Resolved container permissions and Python version issues

### ğŸ“Š Implemented Features
- **Table Creation**: Create partitioned tables using `USING ICEBERG` syntax
- **Data Operations**: Successfully inserted 8 user event records
- **Partitioning Strategy**: Automatic partitioning by date (`days(event_time)`)
- **Metadata Queries**:
  - `.snapshots` - View table snapshot history
  - `.files` - View physical file distribution
  - `.history` - View table change history

### ğŸ¯ Verification Results
- âœ… Created `local.demo.user_events` table
- âœ… Data correctly partitioned to 2024-01-15 and 2024-01-16
- âœ… Generated 2 Parquet files (6+2 records)
- âœ… All metadata queries working normally
- âœ… ACID transaction features verified

## ğŸ“‹ Project Completion Checklist

### Project 1 Checklist âœ…
- [x] Code runs successfully
- [x] Detailed README documentation
- [x] Includes execution steps and result screenshots
- [x] Records problems encountered and solutions
- [x] Summarizes key concepts learned
- [x] Complete Docker environment configuration
- [x] Reproducible Jupyter tutorial execution

### Future Projects Checklist
- [ ] Code runs successfully
- [ ] Detailed README documentation
- [ ] Includes execution steps and result screenshots
- [ ] Records problems encountered and solutions
- [ ] Summarizes key concepts learned

## ğŸ”§ Development Environment Requirements

### Basic Environment âœ…
- Java 11/17/21
- Apache Spark 3.5.0 âœ…
- Docker (for local testing) âœ…
- Iceberg 1.4.3 âœ…

### Cloud Environment (Optional)
- AWS Account (S3, Glue, EMR)
- Azure Account (ADLS, Synapse)
- GCP Account (GCS, Dataproc)

## ğŸ“– Learning Process Summary

### Project 1 Learning Gains âœ…
1. **Environment Setup** - Mastered Docker-based Iceberg development environment âœ…
2. **Basic Concepts** - Understood Spark engine + Iceberg table format architecture âœ…
3. **Practical Operations** - Completed table creation, data insertion, query analysis âœ…
4. **Problem Solving** - Handled Python version conflicts, permission configuration issues âœ…
5. **Feature Verification** - Verified partitioning, transactions, metadata core features âœ…

### Future Project Workflow
1. **Read Project Documentation** - Understand goals and requirements
2. **Environment Preparation** - Set up necessary development environment
3. **Code Implementation** - Complete project code step by step
4. **Testing and Verification** - Run and verify results
5. **Documentation** - Update README and learning notes
6. **Problem Summary** - Record problems encountered and solutions

## ğŸ¯ Current Learning Achievements

After completing Project 1, you can now:

- âœ… Independently set up Iceberg development environment
- âœ… Create and manage basic Iceberg tables
- âœ… Use partitioning strategies to optimize data storage
- âœ… Query and analyze Iceberg table metadata
- âœ… Understand Spark and Iceberg integration mechanisms
- âœ… Troubleshoot and resolve common environment issues

## ğŸš€ Next Steps Recommendations

Based on Project 1's successful completion, suggested continuation order:

1. **Project 2 - Schema Evolution**: Experiment with adding columns and modifying types based on existing tables
2. **Project 3 - Time Travel**: Demonstrate time travel queries using existing snapshots
3. **Project 4 - Cloud Integration**: Migrate environment to cloud platforms
4. **Project 5 - Production Pipeline**: Build complete production data flows

---

**View Completed Project**: [01-first-iceberg-table - First Iceberg Table](01-first-iceberg-table/README.md) âœ…

**Start Next Project**: Schema Evolution Experiments (Coming Soon)